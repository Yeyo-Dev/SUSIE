import json
from sentence_transformers import SentenceTransformer, util
import torch
import os

class SemanticAnalyzer:
    def __init__(self, dataset_path="frases_entrenamiento.json"):
        print("‚è≥ Cargando modelo Sem√°ntico...")
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        self.frases_trampa = []
        self.frases_domesticas = []

        if os.path.exists(dataset_path):
            with open(dataset_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # --- L√ìGICA NUEVA PARA TU JSON ---
                # Recorremos la lista "dataset" y clasificamos seg√∫n el "label"
                for item in data.get("dataset", []):
                    texto = item.get("text")
                    label = item.get("label")
                    
                    if label == "SOSPECHOSO":
                        self.frases_trampa.append(texto)
                    elif label == "DOMESTICO":
                        self.frases_domesticas.append(texto)
                # ---------------------------------
        else:
            # Fallback por si falla el archivo
            self.frases_trampa = ["p√°same la respuesta", "busca en google"]
            self.frases_domesticas = ["mam√° cierra la puerta", "b√°jale a la m√∫sica"]

        # Validaci√≥n de seguridad
        if not self.frases_trampa: print("‚ö†Ô∏è ALERTA: No se cargaron frases de trampa.")
        
        print(f"üß† Memorizando {len(self.frases_trampa)} frases de TRAMPA y {len(self.frases_domesticas)} DOM√âSTICAS...")
        
        # Convertir a Vectores (Embeddings)
        self.embeddings_trampa = self.model.encode(self.frases_trampa, convert_to_tensor=True)
        self.embeddings_domestico = self.model.encode(self.frases_domesticas, convert_to_tensor=True)
        
        print("‚úÖ Analizador listo.")

    def analizar(self, texto_alumno):
        if not texto_alumno or len(texto_alumno.split()) < 2:
            return {"category": "NEUTRAL", "score": 0.0, "flagged": False}

        # 1. Convertir lo que dijo el alumno a vector
        embedding_alumno = self.model.encode(texto_alumno, convert_to_tensor=True)

        # 2. Comparar contra TRAMPAS (Similitud Coseno)
        # util.cos_sim devuelve una matriz, tomamos el valor m√°ximo (la frase a la que m√°s se pareci√≥)
        scores_trampa = util.cos_sim(embedding_alumno, self.embeddings_trampa)
        max_score_trampa = torch.max(scores_trampa).item()

        # 3. Comparar contra DOM√âSTICO
        scores_domestico = util.cos_sim(embedding_alumno, self.embeddings_domestico)
        max_score_domestico = torch.max(scores_domestico).item()

        # 4. L√≥gica de Decisi√≥n
        # Umbral: 0.4 suele ser bueno. 1.0 es id√©ntico. 0.0 es nada que ver.
        UMBRAL_ALERTA = 0.55 

        resultado = {
            "text": texto_alumno,
            "category": "NEUTRAL",
            "score": 0.0,
            "flagged": False
        }

        if max_score_trampa > UMBRAL_ALERTA:
            # Si se parece m√°s a trampa que a dom√©stico
            if max_score_trampa > max_score_domestico:
                resultado["category"] = "SOSPECHOSO"
                resultado["score"] = round(max_score_trampa, 2)
                resultado["flagged"] = True
                return resultado

        if max_score_domestico > UMBRAL_ALERTA:
            resultado["category"] = "DOMESTICO"
            resultado["score"] = round(max_score_domestico, 2)
        
        return resultado

# Instancia global para no recargar el modelo en cada petici√≥n
analyzer_service = SemanticAnalyzer()